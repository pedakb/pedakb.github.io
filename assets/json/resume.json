{"basics":{"name":"Pedram Akbarian","label":"PhD Student","image":"","email":"akbarian@utexas.edu","phone":"","url":"https://pedakb.github.io","summary":"","location":{"address":"","postalCode":"","city":"Austin","countryCode":"US","region":"Texas"},"profiles":[{"network":"GitHub","username":"pedakb","url":"https://github.com/pedakb"}]},"education":[{"institution":"The University of Texas at Austin","location":"Austin, TX","url":"https://www.utexas.edu","area":"Electrical and Computer Engineering","studyType":"PhD","score":"4.0/4.0","courses":[]},{"institution":"University of Tehran","location":"Tehran, Iran","url":"","area":"Electrical Engineering","studyType":"B.Sc.","score":"","courses":["Sparse Subspace Clustering (SSC); Applications in Human Motion Segmentation"]}],"work":[{"name":"The University of Texas at Austin","position":"Research Assistant","url":"https://www.utexas.edu","startDate":"2019-08-01","endDate":"Present","summary":"Focused on theoretical and practical aspects of Mixture of Experts (MoE) in scalable and efficient foundation models.","highlights":[]},{"name":"Toyota InfoTech Lab","position":"Research Intern","url":"","startDate":"2024-01-01","endDate":"Present","summary":"Developing time series foundation models with a focus on scalability and efficiency for handling large-scale data.","highlights":[]},{"name":"CognitiveScale","position":"Research Intern","url":"","startDate":"2021-06-01","endDate":"2021-08-31","summary":"Developed methods for counterfactual explanations in time series data.","highlights":[]}],"awards":[{"title":"Silver Medal in the 26th Iranian National Physics Olympiad","date":"2013-09-01","awarder":"","url":"","summary":""},{"title":"Bronze Medal in the 25th Iranian National Physics Olympiad","date":"2012-09-01","awarder":"","url":"","summary":""},{"title":"Grant from the National Elites Foundation","date":"2014-11-01","awarder":"","url":""}],"publications":[{"name":"Quadratic Gating Functions in Mixture of Experts: A Statistical Insight","publisher":"arXiv","releaseDate":"2024","url":"https://arxiv.org/abs/2410.11222","summary":"Under review."},{"name":"Statistical Advantages of Perturbing Cosine Router in Sparse Mixture of Experts","publisher":"arXiv","releaseDate":"2024","url":"https://arxiv.org/abs/2405.14131","summary":"Under review."},{"name":"Understanding Expert Structures on Minimax Parameter Estimation in Contaminated Mixture of Experts","publisher":"arXiv","releaseDate":"2024","url":"https://arxiv.org/abs/2410.12258","summary":"Under review."},{"name":"Improving Computational Complexity in Statistical Models with Local Curvature Information","publisher":"ICML","releaseDate":"2024","url":"","summary":""},{"name":"Is Temperature Sample Efficient for Softmax Gaussian Mixture of Experts?","publisher":"ICML","releaseDate":"2024","url":"","summary":""},{"name":"A General Theory for Softmax Gating Multinomial Logistic Mixture of Experts","publisher":"ICML","releaseDate":"2024","url":"","summary":""},{"name":"Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts","publisher":"ICLR","releaseDate":"2024","url":"","summary":""},{"name":"Improving Counterfactual Explanations for Time Series Classification Models in Healthcare Settings","publisher":"NeurIPS Workshop","releaseDate":"2022","url":"","summary":""}],"skills":[{"name":"Programming Languages","level":"","icon":"","keywords":["Python (proficient)","C/C++","SQL","MATLAB","R","LATEX"]},{"name":"Software and Frameworks","level":"","icon":"","keywords":["PyTorch (proficient)","TensorFlow","Hugging Face","Git"]}]}